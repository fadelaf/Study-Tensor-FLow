{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This short introduction uses Keras to:\n",
    "\n",
    "Build a neural network that classifies images.\n",
    "Train this neural network.\n",
    "And, finally, evaluate the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare the MNIST dataset. Convert the samples from integers to floating-point numbers:\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train,y_train), (x_test,y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train/255.0, x_test/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow.keras.datasets.mnist' from 'C:\\\\Users\\\\Asus\\\\AppData\\\\Roaming\\\\Python\\\\Python37\\\\site-packages\\\\tensorflow\\\\keras\\\\datasets\\\\mnist\\\\__init__.py'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10)\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each example the model returns a vector of \"logits\" or \"log-odds\" scores, one for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(x_train[:1]).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.85480666,  0.28436685,  0.55803245, -0.12171025,  0.1801103 ,\n",
       "         0.30748367, -0.19648926, -0.13836446, -0.06000577, -0.02869623]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1884401 , 0.1065208 , 0.1400509 , 0.07097042, 0.09597463,\n",
       "        0.10901192, 0.0658569 , 0.06979826, 0.07548755, 0.07788842]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The tf.nn.softmax function converts these logits to \"probabilities\" for each class\n",
    "\n",
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The losses.SparseCategoricalCrossentropy loss takes a vector of logits and a True index and returns a scalar loss for each example.\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.216298"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This loss is equal to the negative log probability of the true class: It is zero if the model is sure of the correct class.\n",
    "\n",
    "# This untrained model gives probabilities close to random (1/10 for each class), so the initial loss should be close to -tf.log(1/10) ~= 2.3.\n",
    "\n",
    "loss_fn(y_train[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss_fn,\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 947us/step - loss: 0.4786 - accuracy: 0.8630\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 910us/step - loss: 0.1528 - accuracy: 0.9555\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 935us/step - loss: 0.1086 - accuracy: 0.9673\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 0.0897 - accuracy: 0.97 - 2s 933us/step - loss: 0.0897 - accuracy: 0.9729\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 908us/step - loss: 0.0732 - accuracy: 0.9773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x231db5aa848>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Model.fit method adjusts the model parameters to minimize the loss:\n",
    "model.fit(x_train,y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.0732 - accuracy: 0.9770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07323525100946426, 0.9769999980926514]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Model.evaluate method checks the models performance, usually on a \"Validation-set\" or \"Test-set\".\n",
    "\n",
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image classifier is now trained to ~98% accuracy on this dataset. To learn more, read the TensorFlow tutorials.\n",
    "\n",
    "If you want your model to return a probability, you can wrap the trained model, and attach the softmax to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilty_model = tf.keras.Sequential([\n",
    "    model, tf.keras.layers.Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x231dca780c8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilty_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[3.97236199e-08, 1.80240782e-08, 1.31701090e-04, 2.21539769e-04,\n",
       "        5.17457847e-11, 2.40065283e-08, 2.94967805e-12, 9.99646187e-01,\n",
       "        2.50635033e-08, 5.05315370e-07],\n",
       "       [1.30318263e-08, 3.41853706e-06, 9.99961019e-01, 1.93690121e-05,\n",
       "        4.20143985e-16, 1.46905541e-06, 5.52933788e-09, 1.08193470e-13,\n",
       "        1.47606661e-05, 2.88295473e-12],\n",
       "       [2.14161247e-07, 9.99796212e-01, 4.67458158e-05, 5.39167195e-06,\n",
       "        1.69472714e-05, 3.69569307e-06, 1.82172698e-06, 1.12031885e-04,\n",
       "        1.52764987e-05, 1.78294283e-06],\n",
       "       [9.99934673e-01, 6.12054984e-09, 5.46905103e-05, 6.73277839e-07,\n",
       "        6.38140318e-10, 9.37751111e-07, 1.80146196e-06, 2.79351889e-06,\n",
       "        1.28160039e-07, 4.25173403e-06],\n",
       "       [5.03628712e-07, 2.07261386e-09, 3.15242892e-06, 6.23847711e-08,\n",
       "        9.99365151e-01, 8.51231334e-08, 1.30896033e-05, 3.48007707e-05,\n",
       "        2.48442262e-07, 5.82941168e-04]], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilty_model(x_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
